{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "spark = SparkSession.builder.appName('svm-app').getOrCreate()\n",
    "\n",
    "df = spark.read.csv('/project/dataset.csv', header = True, inferSchema = True)\n",
    "\n",
    "df = df.sample(withReplacement=True, fraction=0.1, seed=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32229"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.select('title', 'summary', 'labels')\n",
    "# df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_label = {\n",
    "    'E-Sport': 5,\n",
    "    'การเมือง': 1,\n",
    "    'กีฬา': 5,\n",
    "    'กีฬาอื่นๆ': 5,\n",
    "    'ข่าว': None,\n",
    "    'ข่าวบันเทิง': 8,\n",
    "    'คนดังนั่งเขียน': None,\n",
    "    'คอลัมน์': None,\n",
    "    'ตรวจหวย': 2,\n",
    "    'ต่างประเทศ': 3,\n",
    "    'ทองคำ': 2,\n",
    "    'ทันข่าวเด่น': None,\n",
    "    'ทั่วไทย': 9,\n",
    "    'ท่องเที่ยว': 2,\n",
    "    'นักข่าวพลเมือง': None,\n",
    "    'บันเทิง': 8,\n",
    "    'บันเทิงต่างประเทศ': 8,\n",
    "    'บ้าน': None,\n",
    "    'ผู้หญิง': None,\n",
    "    'พระราชสำนัก': 9,\n",
    "    'ฟุตซอล': 5,\n",
    "    'ฟุตบอลยุโรป': 5,\n",
    "    'ฟุตบอลโลก': 5,\n",
    "    'ฟุตบอลไทย': 5,\n",
    "    'ภัยพิบัติ': 10,\n",
    "    'ภูมิภาค': 9,\n",
    "    'มวย/MMA': 5,\n",
    "    'ยานยนต์': 7,\n",
    "    'วอลเลย์บอล': 5,\n",
    "    'วิทยาศาสตร์เทคโนโลยี': 7,\n",
    "    'ศิลปะ-บันเทิง': 8,\n",
    "    'สกู๊ปไทยรัฐ': None,\n",
    "    'สังคม': 1,\n",
    "    'สิ่งแวดล้อม': 10,\n",
    "    'หนัง': 8,\n",
    "    'หนังสือพิมพ์': None,\n",
    "    'หน้าแรก': None,\n",
    "    'หวย': 2,\n",
    "    'อาชญากรรม': 4,\n",
    "    'อาหาร': 11,\n",
    "    'เลือกตั้ง': 1,\n",
    "    'เศรษฐกิจ': 2,\n",
    "    'เอเชียนเกมส์': 5,\n",
    "    'ไทยพีบีเอส อินไซส์': None,\n",
    "    'ไทยรัฐเชียร์ไทยแลนด์': None,\n",
    "    'ไทยลีก': 5,\n",
    "    'ไลฟ์': 12,\n",
    "    'ไลฟ์สไตล์': 12,\n",
    "    'ไอที': 7,\n",
    "    'ไอ้โหด': 4\n",
    "}\n",
    "\n",
    "label_enum = {\n",
    "    1: 'การเมือง',\n",
    "    2: 'เศรษฐกิจ',\n",
    "    3: 'ต่างประเทศ',\n",
    "    4: 'อาชญากรรม',\n",
    "    5: 'กีฬา',\n",
    "    # 6: 'การศึกษา'\n",
    "    7: 'เทคโนโลยี',\n",
    "    8: 'บันเทิง',\n",
    "    9: 'ในประเทศ',\n",
    "    10: 'สิ่งแวดล้อม',\n",
    "    11: 'อาหาร',\n",
    "    12: 'ไลฟ์สไตล์'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "def clean_labels(labels):\n",
    "    if(labels is None):\n",
    "        return None\n",
    "    \n",
    "    labels = labels.split(',')\n",
    "    labels = [map_label[label] if label in map_label else None for label in labels ]\n",
    "    labels = [label_enum[label] for label in labels if label is not None]\n",
    "    \n",
    "    if(len(labels) <= 0):\n",
    "        return None\n",
    "    \n",
    "    # pick max freq label\n",
    "    counter = Counter(labels)\n",
    "    keys = list(counter.keys())\n",
    "    values = list(counter.values())\n",
    "    max_index = np.argmax(values)\n",
    "    label = keys[max_index]\n",
    "    \n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-------------------+--------------------+---------+\n",
      "|               title|             summary|             labels|              tokens|label_pre|\n",
      "+--------------------+--------------------+-------------------+--------------------+---------+\n",
      "|'แซมบ้า' ได้เฮ ทด...|คูตินโญ-เนย์มาร์ ...|     กีฬา,ฟุตบอลโลก|[แซมบ้า, ได้, เฮ,...|     กีฬา|\n",
      "|\"ส.แบดมินตันฯลงโท...| หลังประชุมหารือก...|               กีฬา|[ส, แบดมินตัน, ฯ,...|     กีฬา|\n",
      "|ผู้ต้องสงสัยสวมชุ...|หน่วยงานความมั่นค...|            ภูมิภาค|[ผู้ต้องสงสัย, สว...| ในประเทศ|\n",
      "|ผู้ต้องสงสัยสวมชุ...|หน่วยงานความมั่นค...|            ภูมิภาค|[ผู้ต้องสงสัย, สว...| ในประเทศ|\n",
      "|ยายชาวนาสุรินทร์ ...|คุณยายวัย 67 ปี อ...|       ข่าว,ทั่วไทย|[ยาย, ชาวนา, สุริ...| ในประเทศ|\n",
      "|คนที่เข้ามาใหม่เข...|สุดซึ้ง! สมาชิกพั...|         ข่าว,สังคม|[คน, ที่, เข้ามา,...| การเมือง|\n",
      "|คนที่เข้ามาใหม่เข...|สุดซึ้ง! สมาชิกพั...|         ข่าว,สังคม|[คน, ที่, เข้ามา,...| การเมือง|\n",
      "|คนนับหมื่นแห่รับย...|คนกว่า 2 หมื่นแห่...|       ข่าว,ทั่วไทย|[คน, นับ, หมื่น, ...| ในประเทศ|\n",
      "|มือฆ่าพระ หนีกบดา...|หนุ่มแทงพระ 19 แผ...|         ข่าว,สังคม|[มือ, ฆ่า, พระ, ห...| การเมือง|\n",
      "|\"\"\"ไทยพีบีเอส\"\" ร...|ผู้อำนวยการ ส.ส.ท...|              สังคม|[ไทยพีบีเอส, รับค...| การเมือง|\n",
      "|ชาวนาจังหวัดพิจิต...| ชาวนาจังหวัดพิจิ...|            ภูมิภาค|[ชาวนา, จังหวัด, ...| ในประเทศ|\n",
      "|\"\"\"ทีมหมูป่า\"\" ขอ...|อดีตเยาวชนทีมหมูป...|            ภูมิภาค|[ทีม, หมูป่า, ขอบ...| ในประเทศ|\n",
      "|นิพิฏฐ์ เหน็บ ประ...|นิพิฏฐ์ เหน็บ ประ...|          เลือกตั้ง|[นิ, พิฏฐ์, เหน็บ...| การเมือง|\n",
      "|\"พี่สาวเมีย \"\"เฮี...|พี่สาวเมีย เฮียตี...|       ข่าว,ทั่วไทย|[พี่สาว, เมีย, เฮ...| ในประเทศ|\n",
      "|ตร.ปคม.เร่งทำสำนว...|ผบก.ปคม.เผยผลสอบป...|     ข่าว,อาชญากรรม|[ตรปคม, เร่ง, ทำ,...|อาชญากรรม|\n",
      "|FORTUNER ก็ดี แต่...|ทดสอบเอสยูวีติดหร...|       ข่าว,ยานยนต์|[FORTUNER, ก็, ดี...|เทคโนโลยี|\n",
      "|การบินไทยเลื่อนแผ...|คณะกรรรมการการบิน...|           เศรษฐกิจ|[การ, บิน, ไทย, เ...| เศรษฐกิจ|\n",
      "|ยุ้ย ยอมเปิด! ปมเ...|ยุ้ย จีรนันท์ ยอม...|บันเทิง,ข่าวบันเทิง|[ยุ้ย, ยอม, เปิด,...|  บันเทิง|\n",
      "|ยันปล่อยน้ำหลัง26...|ชลประทานปทุมธานี ...|       ข่าว,ทั่วไทย|[ยัน, ปล่อย, น้ำ,...| ในประเทศ|\n",
      "| ยิงหนุ่มโรงไม้แป...|หนุ่มโรงไม้ยางพาร...|       ข่าว,ทั่วไทย|[ยิง, หนุ่ม, โรง,...| ในประเทศ|\n",
      "+--------------------+--------------------+-------------------+--------------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pre_processing import pre_process\n",
    "\n",
    "udf_pre_process = udf(pre_process, ArrayType(StringType()))\n",
    "udf_clean_labels = udf(clean_labels, StringType())\n",
    "\n",
    "df = df.withColumn(\"tokens\", udf_pre_process(\"title\", \"summary\"))\n",
    "\n",
    "df = df.withColumn(\"label_pre\", udf_clean_labels(\"labels\"))\n",
    "\n",
    "df = df.na.drop()\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer, CountVectorizer\n",
    "\n",
    "countVectors = CountVectorizer(inputCol=\"tokens\", outputCol=\"features\", vocabSize=10000, minDF=5)\n",
    "\n",
    "label_stringIdx = StringIndexer(inputCol = \"label_pre\", outputCol = \"label\")\n",
    "\n",
    "pipeline = Pipeline(stages=[countVectors, label_stringIdx])\n",
    "# Fit the pipeline to training documents.\n",
    "pipelineFit = pipeline.fit(df)\n",
    "dataset = pipelineFit.transform(df)\n",
    "\n",
    "# dataset.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seed for reproducibility\n",
    "(trainingData, testData) = dataset.randomSplit([0.7, 0.3], seed = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+------------------------------+\n",
      "|label|prediction|                   probability|\n",
      "+-----+----------+------------------------------+\n",
      "|  0.0|       0.0|[0.9907679255633245,0.00182...|\n",
      "|  0.0|       0.0|[0.9901946217032246,0.00428...|\n",
      "|  0.0|       0.0|[0.9847903496746296,0.00546...|\n",
      "|  0.0|       0.0|[0.9840291707636613,0.00245...|\n",
      "|  3.0|       0.0|[0.980653875618762,0.001361...|\n",
      "|  3.0|       0.0|[0.9789195826850762,0.00216...|\n",
      "|  0.0|       0.0|[0.9776416070450392,0.00193...|\n",
      "|  0.0|       0.0|[0.9775932311262264,0.00778...|\n",
      "|  0.0|       0.0|[0.9774480271094073,0.00677...|\n",
      "|  0.0|       0.0|[0.9758049064868581,0.00520...|\n",
      "+-----+----------+------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(maxIter=20, regParam=0.3, elasticNetParam=0)\n",
    "\n",
    "lrModel = lr.fit(trainingData)\n",
    "\n",
    "predictions = lrModel.transform(testData)\n",
    "\n",
    "predictions.filter(predictions['prediction'] == 0) \\\n",
    "    .select(\"label\", \"prediction\", \"probability\") \\\n",
    "    .orderBy(\"probability\", ascending=False) \\\n",
    "    .show(n = 10, truncate = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7051871594396206"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "\n",
    "evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrModel.save('/project/lrmodel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegressionModel: uid=LogisticRegression_e9b4b9db04c7, numClasses=10, numFeatures=10000"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.classification import LogisticRegressionModel\n",
    "\n",
    "lrModel = LogisticRegressionModel.load('/project/lrmodel')\n",
    "\n",
    "lrModel"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}